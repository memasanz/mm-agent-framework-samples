{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8396a2",
   "metadata": {},
   "source": [
    "## Bing Grounding Agent with Agent Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1776e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "from agent_framework import ChatAgent, HostedWebSearchTool\n",
    "from agent_framework_azure_ai import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv \n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated\n",
    "from pydantic import Field\n",
    "\n",
    "# Import for router hints support\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187399d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True) # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b24371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent created and ready to use!\n"
     ]
    }
   ],
   "source": [
    "def write_to_file(model_name: str, question: str, response: str):\n",
    "        try:\n",
    "            print('write to csv file.')\n",
    "            '''write to a csv file append a row to a column response and model name'''\n",
    "            with open(\"bing_grounding_agent_responses.csv\", \"a\") as f:\n",
    "                f.write(f'\"{model_name}\",\"{question.replace(chr(10), \" \").replace(chr(13), \" \")}\",\"{response.replace(chr(10), \" \").replace(chr(13), \" \")}\"\\n')\n",
    "            print('‚úÖ Successfully wrote to file')\n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Error writing to file: {e}')\n",
    "\n",
    "\n",
    "def ask_question_with_model_router(question: Annotated[str, Field(description=\"Ask Azure Model Router Question\")]) -> str:\n",
    "        print('üîç DEBUG: ask_question_with_model_router FUNCTION WAS CALLED!')\n",
    "        print('+++++++++++++++++++++++++++++++++++++++++++')\n",
    "        print(\"QUESTION RECEIVED IN TOOL:\")\n",
    "        print(question)\n",
    "        print('+++++++++++++++++++++++++++++++++++++++++++')\n",
    "        \n",
    "        try:\n",
    "            # Use standard AzureOpenAI client\n",
    "            endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "            api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "            deployment_name = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "            \n",
    "            print(f\"Using deployment: {deployment_name}\")\n",
    "            print(f\"Endpoint: {endpoint}\")\n",
    "            \n",
    "            client = AzureOpenAI(\n",
    "                azure_endpoint=endpoint,\n",
    "                api_key=api_key,\n",
    "                api_version=\"2024-05-01-preview\"\n",
    "            )\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant. You are asked complex questions. Think hard before answering. Use Reasoning to answer the question.\"},\n",
    "                    {\"role\": \"user\", \"content\": question}\n",
    "                ],\n",
    "                max_tokens=30657\n",
    "            )\n",
    "\n",
    "            print(\"completion model used: \" + completion.model)\n",
    "            \n",
    "            # Extract response text\n",
    "            response_text = completion.choices[0].message.content\n",
    "            print(\"About to write to file\")\n",
    "            write_to_file(completion.model, question, response_text)\n",
    "            print(\"Returned from write_to_file\")\n",
    "            return f\"content: {response_text}, model: {completion.model}\"\n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Error in ask_question_with_model_router: {e}')\n",
    "            raise\n",
    "\n",
    "    \n",
    "\n",
    "# Create the agent\n",
    "bing_search_tool = HostedWebSearchTool(\n",
    "    name=\"BingGroundingSearch\",\n",
    "    description=\"Search the web for current information using Bing\",\n",
    ")\n",
    "\n",
    "instructions = \"\"\"\n",
    "\n",
    "You are ‚ÄúRouter Test Harness‚Äù.\n",
    "\n",
    "MISSION\n",
    "- When the user submits a question, DO NOT answer it.\n",
    "- Rewrite the question into a higher-complexity ‚Äútest prompt‚Äù designed to elicit a reasoning model from the Azure Model Router.\n",
    "- Send ONLY the rewritten prompt (not the original) to the `run_router` tool.\n",
    "- Ask for pros and cons, ask for companison analysis, ask for step by step reasoning, or ask for a plan with steps to solve the problem.\n",
    "\n",
    "\n",
    "PIPELINE\n",
    "(1) REWRITE\n",
    "- Create a single-turn test prompt that forces: multi-step planning, constraints, verification, and synthesis.\n",
    "- Add domain scaffolding (planning, constraints, success criteria, intermediate representation).\n",
    "- Keep it concise (< 500 tokens) and self-contained. Do NOT include conversation history.\n",
    "- Use words like: \"think harder\", \"plan\", \"steps\", \"constraints\", \"verify\", \"synthesize\", \"criteria\", \"representation\".\n",
    "- flagging issues and challenging assumptions\n",
    "- You should not be fast, you should take your time before responding.\n",
    "\n",
    "(2) ROUTE (TOOL: run_router)\n",
    "- Input: the rewritten prompt only.\n",
    "- If a reasoning model was NOT selected, perform up to 2 escalations (see below), each time rewriting to increase complexity, then call `run_router` again. Never exceed 3 runs total.\n",
    "\"\"\"\n",
    "       \n",
    "client = AzureAIAgentClient(async_credential=AzureCliCredential())\n",
    "agent = ChatAgent(\n",
    "    chat_client=client,\n",
    "    name=\"BingGroundingSearchAgent\",\n",
    "    instructions=(\n",
    "        instructions\n",
    "    ),\n",
    "    tools=[ ask_question_with_model_router]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agent created and ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a12d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_agent(user_input: str):\n",
    "    \"\"\"Ask the agent a question and get a response\"\"\"\n",
    "    print(\"=== Azure AI Agent with Bing Grounding Search ===\\n\")\n",
    "    print(f\"User: {user_input}\")\n",
    "\n",
    "    print(\"üîç DEBUG: About to call agent.run with tool_choice\")\n",
    "    response_text = await agent.run(user_input, tool_choice=ask_question_with_model_router)\n",
    "    print(f\"üîç DEBUG: Agent returned. Response type: {type(response_text)}\")\n",
    "    print(f\"Agent: {response_text.text}\\n\")\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7db177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aaec77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "=== Azure AI Agent with Bing Grounding Search ===\n",
      "\n",
      "User: Give me a SQL Server 2022 scripts to create a datawarehouse for the purchase department, and provide code explanations, generate  seed script, and calculate metrics for seed data following the EBITA  model.  Using the generated seed script, analyze the financial statements for the last 3 years, identify discrepancies, and proces a five-step reasoning report with citations from teh annexed documents using formal rigor\n",
      "üîç DEBUG: About to call agent.run with tool_choice\n",
      "üîç DEBUG: ask_question_with_model_router FUNCTION WAS CALLED!\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "QUESTION RECEIVED IN TOOL:\n",
      "Develop a formal multi-step analysis of constructing a data warehouse for a purchase department using SQL Server 2022. Begin by planning and describing the key entities and tables relevant for purchase and financial analysis according to EBITA (Earnings Before Interest, Taxes, and Amortization) model constraints. Next, write scripts to create the schema with annotated code explanations and generate a seed script to populate three years of representative financial data. Then, define SQL queries to calculate EBITA-related metrics, ensuring each query steps through validation of business logic. After seeding the data, compare and analyze the simulated financial statements for the last three years, identifying discrepancies using formal criteria. Finally, synthesize a five-step reasoning report summarizing insights, highlighting data issues, and providing citations from assumed annexed documents as evidence, maintaining business analysis rigor throughout. Explicitly list all constraints assumed at each stage and clarify verification measures for each output.\n",
      "+++++++++++++++++++++++++++++++++++++++++++\n",
      "Using deployment: model-router\n",
      "Endpoint: https://mmz-ai-foundry-eastus2.openai.azure.com/\n",
      "completion model used: gpt-5-mini-2025-08-07\n",
      "About to write to file\n",
      "write to csv file.\n",
      "‚ùå Error writing to file: 'charmap' codec can't encode character '\\u2192' in position 3449: character maps to <undefined>\n",
      "Returned from write_to_file\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(_)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m ask_agent(\u001b[33m\"\u001b[39m\u001b[33mGive me a SQL Server 2022 scripts to create a datawarehouse for the purchase department, and provide code explanations, generate  seed script, and calculate metrics for seed data following the EBITA  model.  Using the generated seed script, analyze the financial statements for the last 3 years, identify discrepancies, and proces a five-step reasoning report with citations from teh annexed documents using formal rigor\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mask_agent\u001b[39m\u001b[34m(user_input)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç DEBUG: About to call agent.run with tool_choice\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response_text = \u001b[38;5;28;01mawait\u001b[39;00m agent.run(user_input, tool_choice=ask_question_with_model_router)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç DEBUG: Agent returned. Response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response_text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_text.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\memasanz\\repos\\agent-framework-exploration\\.venv\\Lib\\site-packages\\agent_framework\\_middleware.py:1242\u001b[39m, in \u001b[36muse_agent_middleware.<locals>.middleware_enabled_run\u001b[39m\u001b[34m(self, messages, thread, middleware, **kwargs)\u001b[39m\n\u001b[32m   1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m AgentRunResponse()\n\u001b[32m   1241\u001b[39m \u001b[38;5;66;03m# No middleware, execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_run(\u001b[38;5;28mself\u001b[39m, normalized_messages, thread=thread, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\memasanz\\repos\\agent-framework-exploration\\.venv\\Lib\\site-packages\\agent_framework\\observability.py:1097\u001b[39m, in \u001b[36m_trace_agent_run.<locals>.trace_run\u001b[39m\u001b[34m(self, messages, thread, **kwargs)\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1096\u001b[39m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_func(\u001b[38;5;28mself\u001b[39m, messages=messages, thread=thread, **kwargs)\n\u001b[32m   1098\u001b[39m attributes = _get_span_attributes(\n\u001b[32m   1099\u001b[39m     operation_name=OtelAttr.AGENT_INVOKE_OPERATION,\n\u001b[32m   1100\u001b[39m     provider_name=provider_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1106\u001b[39m     **kwargs,\n\u001b[32m   1107\u001b[39m )\n\u001b[32m   1108\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _get_span(attributes=attributes, span_name_attribute=OtelAttr.AGENT_NAME) \u001b[38;5;28;01mas\u001b[39;00m span:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\memasanz\\repos\\agent-framework-exploration\\.venv\\Lib\\site-packages\\agent_framework\\_agents.py:823\u001b[39m, in \u001b[36mChatAgent.run\u001b[39m\u001b[34m(self, messages, thread, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_chat_options, **kwargs)\u001b[39m\n\u001b[32m    802\u001b[39m     final_tools.extend(mcp_server.functions)\n\u001b[32m    804\u001b[39m co = run_chat_options & ChatOptions(\n\u001b[32m    805\u001b[39m     model_id=model_id,\n\u001b[32m    806\u001b[39m     conversation_id=thread.service_thread_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    821\u001b[39m     **(additional_chat_options \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    822\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chat_client.get_response(messages=thread_messages, chat_options=co, **kwargs)\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_thread_with_type_and_conversation_id(thread, response.conversation_id)\n\u001b[32m    827\u001b[39m \u001b[38;5;66;03m# Ensure that the author name is set for each message in the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\memasanz\\repos\\agent-framework-exploration\\.venv\\Lib\\site-packages\\agent_framework\\_tools.py:1269\u001b[39m, in \u001b[36m_handle_function_calls_response.<locals>.decorator.<locals>.function_invocation_wrapper\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1265\u001b[39m tools = _extract_tools(kwargs)\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m function_calls \u001b[38;5;129;01mand\u001b[39;00m tools:\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# Use the stored middleware pipeline instead of extracting from kwargs\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# because kwargs may have been modified by the underlying function\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     function_call_results: \u001b[38;5;28mlist\u001b[39m[Contents] = \u001b[38;5;28;01mawait\u001b[39;00m _execute_function_calls(\n\u001b[32m   1270\u001b[39m         custom_args=kwargs,\n\u001b[32m   1271\u001b[39m         attempt_idx=attempt_idx,\n\u001b[32m   1272\u001b[39m         function_calls=function_calls,\n\u001b[32m   1273\u001b[39m         tools=tools,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1274\u001b[39m         middleware_pipeline=stored_middleware_pipeline,\n\u001b[32m   1275\u001b[39m     )\n\u001b[32m   1276\u001b[39m     \u001b[38;5;66;03m# add a single ChatMessage to the response with the results\u001b[39;00m\n\u001b[32m   1277\u001b[39m     result_message = ChatMessage(role=\u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m, contents=function_call_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\memasanz\\repos\\agent-framework-exploration\\.venv\\Lib\\site-packages\\agent_framework\\_tools.py:1102\u001b[39m, in \u001b[36m_execute_function_calls\u001b[39m\u001b[34m(custom_args, attempt_idx, function_calls, tools, middleware_pipeline)\u001b[39m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m   1096\u001b[39m         FunctionApprovalRequestContent(\u001b[38;5;28mid\u001b[39m=fcc.call_id, function_call=fcc)\n\u001b[32m   1097\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m fcc \u001b[38;5;129;01min\u001b[39;00m function_calls\n\u001b[32m   1098\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fcc, FunctionCallContent)\n\u001b[32m   1099\u001b[39m     ]\n\u001b[32m   1101\u001b[39m \u001b[38;5;66;03m# Run all function calls concurrently\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*[\n\u001b[32m   1103\u001b[39m     _auto_invoke_function(\n\u001b[32m   1104\u001b[39m         function_call_content=function_call,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1105\u001b[39m         custom_args=custom_args,\n\u001b[32m   1106\u001b[39m         tool_map=tool_map,\n\u001b[32m   1107\u001b[39m         sequence_index=seq_idx,\n\u001b[32m   1108\u001b[39m         request_index=attempt_idx,\n\u001b[32m   1109\u001b[39m         middleware_pipeline=middleware_pipeline,\n\u001b[32m   1110\u001b[39m     )\n\u001b[32m   1111\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m seq_idx, function_call \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(function_calls)\n\u001b[32m   1112\u001b[39m ])\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    print(_)\n",
    "    await ask_agent(\"Give me a SQL Server 2022 scripts to create a datawarehouse for the purchase department, and provide code explanations, generate  seed script, and calculate metrics for seed data following the EBITA  model.  Using the generated seed script, analyze the financial statements for the last 3 years, identify discrepancies, and proces a five-step reasoning report with citations from teh annexed documents using formal rigor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f69d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
